{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "new_with_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PdoQVJZ4VzO3",
        "H5npbzPM0_m8",
        "a3YYmCakWFM3",
        "qVDnKBw3LAx5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uqOpbQA6l6Dd",
        "outputId": "59f6a255-d34e-4d9d-9860-3ec12c62838b"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVyO6Pn0kyYR",
        "outputId": "6ab5c351-ad08-4a36-ea5e-a7b2afae469a"
      },
      "source": [
        "cd drive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU1SYJVfkcFn"
      },
      "source": [
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm\n",
        "from random import shuffle, choice, uniform\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSKkhAYponPU"
      },
      "source": [
        "from os.path import isdir, dirname, abspath, join\r\n",
        "from os import makedirs\r\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, TensorBoard, \r\n",
        "                                        EarlyStopping, LearningRateScheduler)\r\n",
        "from io import BytesIO\r\n",
        "from natsort import natsorted\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras import Sequential,Model\r\n",
        "\r\n",
        "from tensorflow.keras.applications import (DenseNet201, InceptionV3, MobileNetV2,\r\n",
        "                                           ResNet101, Xception, EfficientNetB7,VGG19, NASNetLarge)\r\n",
        "from tensorflow.keras.applications import (densenet, inception_v3, mobilenet_v2,\r\n",
        "                                           resnet, xception, efficientnet, vgg19, nasnet)\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\r\n",
        "from tensorflow.keras.optimizers import SGD, Adam\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling, Resizing\r\n",
        "from tensorflow.keras.utils import Progbar"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI0DAkYsVqJa"
      },
      "source": [
        "# Define paths and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTwKTTy7kcCa",
        "outputId": "5477fadd-c0dc-4dab-d19a-513486d63c87"
      },
      "source": [
        "ROOT = '/content/drive/MyDrive'\n",
        "data_path = 'cropped/'\n",
        "train_path = data_path + 'train'\n",
        "val_path = data_path + 'val'\n",
        "\n",
        "labels = {v:k for k, v in enumerate(listdir(train_path))}\n",
        "labels"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'black': 11,\n",
              " 'blue': 1,\n",
              " 'brown': 2,\n",
              " 'green': 3,\n",
              " 'grey': 4,\n",
              " 'orange': 0,\n",
              " 'pink': 5,\n",
              " 'purple': 6,\n",
              " 'red': 7,\n",
              " 'silver': 8,\n",
              " 'white': 9,\n",
              " 'yellow': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdoQVJZ4VzO3"
      },
      "source": [
        "# Generate TFRecords by compressing jpeg files and their corresponding one hot labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUHedCZU0jG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4065e9f2-52bb-4b8c-cafb-c566e6e2baad"
      },
      "source": [
        "# https://medium.com/ymedialabs-innovation/how-to-use-tfrecord-with-datasets-and-iterators-in-tensorflow-with-code-samples-ffee57d298af\n",
        "\n",
        "class GenerateTFRecord:\n",
        "    def __init__(self, path):\n",
        "        self.path = Path(path)\n",
        "        self.labels = {v:k for k, v in enumerate(listdir(path))}\n",
        "\n",
        "    def convert_image_folder(self, tfrecord_file_name):\n",
        "        # Get all file names of images present in folder\n",
        "        img_paths = list(self.path.rglob('*.jpg'))\n",
        "        shuffle(img_paths)\n",
        "        img_paths = img_paths\n",
        "\n",
        "        with tf.io.TFRecordWriter(tfrecord_file_name) as writer:\n",
        "            for img_path in tqdm(img_paths, desc='images converted'):\n",
        "                example = self._convert_image(img_path)\n",
        "                writer.write(example.SerializeToString())\n",
        "\n",
        "    def _convert_image(self, img_path):\n",
        "        label = self.labels[img_path.parent.stem]\n",
        "        img_shape = mpimg.imread(img_path).shape\n",
        "        # print(tf.one_hot(label, depth=len(self.labels), on_value=1, off_value=0))\n",
        "        # Read image data in terms of bytes\n",
        "        with tf.io.gfile.GFile(img_path, 'rb') as fid:\n",
        "            image_data = fid.read()\n",
        "\n",
        "        example = tf.train.Example(features = tf.train.Features(feature = {\n",
        "            'image': tf.train.Feature(bytes_list = tf.train.BytesList(value = [image_data])),\n",
        "            'label': tf.train.Feature(int64_list = tf.train.Int64List(value = tf.one_hot(label, \n",
        "                                                                                         depth=len(labels), \n",
        "                                                                                         on_value=1, \n",
        "                                                                                         off_value=0))),\n",
        "        }))\n",
        "        return example\n",
        "\n",
        "\n",
        "t = GenerateTFRecord(path=train_path)\n",
        "t.convert_image_folder('orig_data.tfrecord')\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "images converted: 100%|██████████| 4881/4881 [33:30<00:00,  2.43it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5npbzPM0_m8"
      },
      "source": [
        "# Defining dict for models and their corresponding blocks for unfreeze during transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALEpyhD70qup"
      },
      "source": [
        "models = {\n",
        "    'densenet': DenseNet201,\n",
        "    'xception': Xception,\n",
        "    'inceptionv3': InceptionV3,\n",
        "    'effecientnetb7': EfficientNetB7,\n",
        "    'vgg19': VGG19,\n",
        "    'nasnetlarge': NASNetLarge,\n",
        "    'mobilenetv2': MobileNetV2,\n",
        "    'resnet': ResNet101\n",
        "}\n",
        "\n",
        "# models['densenet']()\n",
        "\n",
        "preprocess_pipeline = {\n",
        "    'densenet': densenet.preprocess_input,\n",
        "    'xception': xception.preprocess_input,\n",
        "    'inceptionv3': inception_v3.preprocess_input,\n",
        "    'effecientnetb7': efficientnet.preprocess_input,\n",
        "    'vgg19': vgg19.preprocess_input,\n",
        "    'nasnetlarge': nasnet.preprocess_input,\n",
        "    'mobilenetv2': mobilenet_v2.preprocess_input,\n",
        "    'resnet': resnet.preprocess_input\n",
        "}\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3YYmCakWFM3"
      },
      "source": [
        "# Utility functions:\r\n",
        "- `generator`: Configuring `tf.data` generator.\r\n",
        "- `augment`: Augmentation using `tf.image` 90 degree rotation, flip and resize.\r\n",
        "- `_parse_function`: Function to parse tfrecords to tensor.\r\n",
        "- `configure_for_performance`: Configuring caching mechanism for tf.data\r\n",
        "- Sample test for validating code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb8N3Nwyk79x"
      },
      "source": [
        "model_name = 'xception'\r\n",
        "def augment(image, rotate=True, flip_vertical=True, \r\n",
        "            flip_horizontal=True, random_brightness=True):\r\n",
        "\r\n",
        "    image = tf.cast(image, tf.float32)\r\n",
        "    image = tf.expand_dims(image, axis=0)\r\n",
        "    image = preprocess_pipeline[model_name](image)\r\n",
        "    image = tf.squeeze(image, axis=0)\r\n",
        "\r\n",
        "    image = tf.reverse(image, axis=[0]) if flip_vertical else image   # flip top to bottom.\r\n",
        "    image = tf.reverse(image, axis=[1]) if flip_horizontal else image # flip left to right.\r\n",
        "    # Flip up to bottom can be generated if rotate function given k = 2 in rotate part.\r\n",
        "\r\n",
        "    if rotate:\r\n",
        "        image = tf.expand_dims(image, axis=0)\r\n",
        "        image = tf.image.rot90(image, k=choice([1,2,3])) # Random rotate\r\n",
        "        image = tf.squeeze(image, axis=0)\r\n",
        "\r\n",
        "    if random_brightness:\r\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\r\n",
        "\r\n",
        "    return image\r\n",
        "\r\n",
        "def _augment_function(image, label):\r\n",
        "    flip_vertical = np.random.uniform(0, 1) >= 0.5\r\n",
        "    flip_horizontal = np.random.uniform(0, 1) >= 0.5\r\n",
        "    rotate = np.random.uniform(0, 1) >= 0.5\r\n",
        "    random_brightness = np.random.uniform(0, 1) >= 0.5\r\n",
        "\r\n",
        "    image = augment(image,\r\n",
        "                    flip_horizontal=flip_horizontal, \r\n",
        "                    flip_vertical=flip_vertical,\r\n",
        "                    rotate=rotate,\r\n",
        "                    random_brightness=random_brightness)\r\n",
        "    \r\n",
        "    # matplotlib wants [0,1] values\r\n",
        "    image = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\r\n",
        "    \r\n",
        "    return image, label\r\n",
        "\r\n",
        "def _parse_function(tfrecord):\r\n",
        "    img_size = 224\r\n",
        "    # Extract features using the keys set during creation\r\n",
        "    features = {\r\n",
        "        'image': tf.io.FixedLenFeature([], tf.string),\r\n",
        "        'label': tf.io.FixedLenFeature([12], tf.int64)\r\n",
        "    }\r\n",
        "    # Extract the data record\r\n",
        "    sample = tf.io.parse_single_example(tfrecord, features)\r\n",
        "    image = tf.image.decode_jpeg(sample['image'])\r\n",
        "\r\n",
        "    image = tf.image.resize(image, [img_size, img_size], \r\n",
        "                            method=tf.image.ResizeMethod.BILINEAR)\r\n",
        "    # augmentation\r\n",
        "    label = sample['label']\r\n",
        "    return image, label\r\n",
        "\r\n",
        "\r\n",
        "def configure_for_performance(ds, buffer_size, batch_size):\r\n",
        "    ds = ds.cache()\r\n",
        "    ds = ds.batch(batch_size)\r\n",
        "    ds = ds.prefetch(buffer_size=buffer_size)\r\n",
        "    return ds\r\n",
        "\r\n",
        "\r\n",
        "def generator(tfrecord_file, batch_size, n_data, validation_ratio, \r\n",
        "              reshuffle_each_iteration=False):\r\n",
        "    reader = tf.data.TFRecordDataset(filenames=[tfrecord_file])\r\n",
        "    reader.shuffle(n_data, reshuffle_each_iteration=reshuffle_each_iteration)\r\n",
        "    AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
        "\r\n",
        "    val_size = int(n_data * validation_ratio)\r\n",
        "    train_ds = reader.skip(val_size)\r\n",
        "    val_ds = reader.take(val_size)\r\n",
        "\r\n",
        "    train_ds = train_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\r\n",
        "    train_ds = train_ds.map(_augment_function, num_parallel_calls=AUTOTUNE)\r\n",
        "    train_ds = configure_for_performance(train_ds, AUTOTUNE, batch_size).repeat()\r\n",
        "\r\n",
        "    val_ds = val_ds.map(_parse_function, num_parallel_calls=AUTOTUNE)\r\n",
        "    val_ds = val_ds.map(_augment_function, num_parallel_calls=AUTOTUNE)\r\n",
        "    val_ds = configure_for_performance(val_ds, AUTOTUNE, batch_size).repeat()\r\n",
        "    return train_ds, val_ds\r\n",
        "\r\n",
        "tfrecord_file = 'cropped_data.tfrecord'\r\n",
        "validation_ratio = 0.2\r\n",
        "# n_data = len(list(Path('original/train').rglob('*.jpg')))\r\n",
        "n_data = 50\r\n",
        "train, val = generator(tfrecord_file, 2, n_data, validation_ratio, True)\r\n",
        "\r\n",
        "# i = 0\r\n",
        "# for x, y in train:\r\n",
        "#   print(list(labels.keys())[int(tf.argmax(y[0]))])\r\n",
        "#   i+=1\r\n",
        "#   if i == 1:\r\n",
        "#     break\r\n",
        "# x, y = train[0]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVDnKBw3LAx5"
      },
      "source": [
        "# Utility Functions for training:\r\n",
        "- `create_model`: creates deep model / freeze or unfreeze layers / adds classification layers.\r\n",
        "- `scheduler`: reduces the learning rate over epochs.\r\n",
        "- `manage_runs`: organizes paths to record the callbacks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzvJAKvx4d4R"
      },
      "source": [
        "def create_model(optimizer, name='densenet', include_compile=True, blocks_to_train=[]):\r\n",
        "    base_model = models[name](include_top=False, weights='imagenet')\r\n",
        "    # model = Model(base_model.inputs, base_model.layers[-1].output)\r\n",
        "\r\n",
        "    if bool(blocks_to_train):\r\n",
        "        for block in blocks_to_train:\r\n",
        "            for layer in base_model.layers:\r\n",
        "                if block in layer.name:\r\n",
        "                  layer.trainable = True\r\n",
        "                else:\r\n",
        "                  layer.trainable = False\r\n",
        "\r\n",
        "    x = GlobalAveragePooling2D()(base_model.layers[-1].output)\r\n",
        "    x = Dense(1024, activation='relu')(x)\r\n",
        "    output = Dense(12, activation='softmax')(x)\r\n",
        "\r\n",
        "    model = Model(base_model.inputs, output)\r\n",
        "    \r\n",
        "    if include_compile:\r\n",
        "        model.compile(loss='categorical_crossentropy',\r\n",
        "                      optimizer=optimizer,\r\n",
        "                      metrics=['accuracy'])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def scheduler(epoch):\r\n",
        "    # Every 10 epochs, the learning rate is reduced to 1/10 of the original\r\n",
        "    if epoch == 10:\r\n",
        "        lr = K.get_value(model.optimizer.lr)\r\n",
        "        K.set_value(model.optimizer.lr, lr * 0.1)\r\n",
        "\r\n",
        "    if epoch == 100:\r\n",
        "        lr = K.get_value(model.optimizer.lr)\r\n",
        "        K.set_value(model.optimizer.lr, lr * 0.1)\r\n",
        "\r\n",
        "    # if epoch % 10 == 0 and epoch != 0:\r\n",
        "    #     lr = K.get_value(model.optimizer.lr)\r\n",
        "    #     K.set_value(model.optimizer.lr, lr * 0.5)\r\n",
        "    return K.get_value(model.optimizer.lr)\r\n",
        "\r\n",
        "\r\n",
        "def generate_path(path_to_output, last_run=False):\r\n",
        "    runs = natsorted([path for path in listdir(path_to_output) if path.startswith(\"run_tf_data\")])\r\n",
        "    if last_run:\r\n",
        "        if not bool(runs):\r\n",
        "          path = join(path_to_output, \"run_tf_data_1\")\r\n",
        "        else:\r\n",
        "          path = join(path_to_output, runs[-1])\r\n",
        "\r\n",
        "        return path\r\n",
        "    if not bool(runs):\r\n",
        "        path = join(path_to_output, 'run_tf_data_1')\r\n",
        "    else:\r\n",
        "        f = runs[-1].rsplit(\"data_\")[1]\r\n",
        "        path = join(path_to_output, 'run_tf_data_' + str(int(f) + 1))\r\n",
        "    \r\n",
        "    return path\r\n",
        "\r\n",
        "\r\n",
        "def manage_runs(out_path, save_weights=True, reduce_lr_on_epoch=False, \r\n",
        "                reduce_lr_on_plateau=False):\r\n",
        "    # get the root path of the project.\r\n",
        "    assert isdir(out_path), \"Path does not exist.\"\r\n",
        "    # root = dirname(abspath(__file__))\r\n",
        "    # Absolute path to output directory.\r\n",
        "    out_path = join(ROOT, out_path)\r\n",
        "    path_to_save = generate_path(out_path)\r\n",
        "\r\n",
        "    makedirs(path_to_save, exist_ok=True)\r\n",
        "    callbacks = []\r\n",
        "\r\n",
        "    if save_weights:\r\n",
        "        weights_dir = f'{path_to_save}/weights/'\r\n",
        "        makedirs(weights_dir)\r\n",
        "        checkpoint = ModelCheckpoint(filepath=weights_dir + '/epoch.{epoch}.loss.{val_loss:.3f}.h5',\r\n",
        "                                     save_best_only=True,\r\n",
        "                                     monitor='val_loss',\r\n",
        "                                     save_weights_only=True)\r\n",
        "        callbacks.append(checkpoint)\r\n",
        "\r\n",
        "    if reduce_lr_on_epoch:\r\n",
        "        lr_epoch = LearningRateScheduler(scheduler)\r\n",
        "        callbacks.append(lr_epoch)\r\n",
        "\r\n",
        "    if reduce_lr_on_plateau:\r\n",
        "        lr_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=50, \r\n",
        "                                    min_lr=1e-5)\r\n",
        "        callbacks.append(lr_plateau)\r\n",
        "\r\n",
        "    return callbacks"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF8xYeqaxGMZ"
      },
      "source": [
        "# Tensorboard Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A8GHixlwI_L"
      },
      "source": [
        "def plot_to_image(figure):\n",
        "    # save plot to png file\n",
        "    buf = BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    plt.close(figure)\n",
        "\n",
        "    buf.seek(0)\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "\n",
        "    # Add the batch dimension\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "def image_to_grid(data, labels, class_names):\n",
        "\n",
        "    assert data.ndim == 4\n",
        "    figure = plt.figure(figsize=(10,10))\n",
        "    num_images = data.shape[0]\n",
        "    size = int(np.ceil(np.sqrt(num_images)))\n",
        "    # class_names[int(tf.argmax(y[0]))\n",
        "    for i in range(data.shape[0]):\n",
        "        plt.subplot(size, size, i+1, \n",
        "                    title=class_names[int(tf.argmax(labels[i]))])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        \n",
        "        # Grayscale images\n",
        "        # if data.shape[3] == 1:\n",
        "        #     plt.imshow(data[i], cmap=plt.cm.binary)\n",
        "        # else:\n",
        "        #     plt.imshow(data[i])\n",
        "\n",
        "    return figure\n",
        "    \n",
        "def get_confusion_matrix(y_labels, logits, class_names):\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    labels = tf.argmax(y_labels, axis=1).numpy()\n",
        "    cm = confusion_matrix(\n",
        "        labels,\n",
        "        preds, \n",
        "        labels=np.arange(len(class_names))\n",
        "    )\n",
        "\n",
        "    return cm\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    size=len(class_names)\n",
        "    figure=plt.figure(figsize=(size, size))\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "\n",
        "    indices = np.arange(len(class_names))\n",
        "    \n",
        "    plt.xticks(indices, class_names, rotation=45)\n",
        "    plt.yticks(indices, class_names)\n",
        "    cm=np.around(\n",
        "        cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=3\n",
        "    )\n",
        "\n",
        "    threshold = cm.max() / 2.0\n",
        "\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            color = 'white' if cm[i,j] > threshold else \"black\"\n",
        "\n",
        "            plt.text(\n",
        "                i, j, cm[i, j], horizontalalignment=\"center\", color=color, \n",
        "            )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.xlabel(\"True Label\")\n",
        "    plt.ylabel(\"Prediction label\")\n",
        "    cm_image = plot_to_image(figure)\n",
        "    \n",
        "    return  cm_image\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4FZRA4OYhm4"
      },
      "source": [
        "# Defining model parameters and generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr52oWEyYxAC"
      },
      "source": [
        "\"\"\"\r\n",
        "########################################################\r\n",
        "##################  train parameters  ##################\r\n",
        "########################################################\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "n_data = len(list(Path(data_path).rglob('*.jpg')))\r\n",
        "validation_ratio = 0.2\r\n",
        "val_size = int(n_data * validation_ratio)\r\n",
        "train_size = n_data - val_size\r\n",
        "batch_size = 64\r\n",
        "n_epochs = 2\r\n",
        "n_workers = 5\r\n",
        "\r\n",
        "train_steps = train_size//(batch_size)\r\n",
        "val_steps = val_size//(batch_size)\r\n",
        "\r\n",
        "\r\n",
        "filename = '/content/drive/MyDrive/cropped_data.tfrecord'\r\n",
        "\r\n",
        "\r\n",
        "train_ds, val_ds = generator(filename,\r\n",
        "                            batch_size=batch_size,\r\n",
        "                            n_data=n_data,\r\n",
        "                            validation_ratio=validation_ratio,\r\n",
        "                            reshuffle_each_iteration=True)\r\n",
        "\r\n",
        "# callbacks = manage_runs('runs',\r\n",
        "#                         save_weights=False,\r\n",
        "#                         reduce_lr_on_epoch=True,\r\n",
        "#                         reduce_lr_on_plateau=False)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWjbuSbPdKHR"
      },
      "source": [
        "!rm -r runs/*"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YgAYPPfYrji"
      },
      "source": [
        "# Training process\r\n",
        "\r\n",
        "|model|val loss|val acc|wall time|epochs|generator\r\n",
        "|:---:|:---:|:---:|:---:|:---:|:---:|\r\n",
        "|densnet 121|1.13|0.6633|1h 21min 2s|300|`tf.data`|\r\n",
        "\r\n",
        "Wall time: 1h 21min 2s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOSYZOXDcFO_"
      },
      "source": [
        "# TensorFlow Custom Loop\n",
        "----\n",
        "**Includes:**\n",
        "- Generate data with `tf.data.Dataset`\n",
        "- `TFRecord`\n",
        "- Tensorboard\n",
        "- - validation data images\n",
        "- - images of cofusion matrix\n",
        "- - Train/Validation accuracy and loss\n",
        "- Transfer Learning\n",
        "- Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF7gIyCGNnOS"
      },
      "source": [
        "\"\"\" \n",
        "########################################################\n",
        "##################  configure tensorboard  #############\n",
        "########################################################\n",
        "\"\"\"\n",
        "\n",
        "# model_name = choice(list(models.keys()))\n",
        "model_name = 'xception'\n",
        "# blocks_to_train = block_trainables[model_name]\n",
        "\n",
        "path_to_run = generate_path(join(ROOT, 'runs'), last_run=True)\n",
        "\n",
        "tb_train_path = join(path_to_run, 'logs','train')\n",
        "tb_test_path = join(path_to_run, 'logs', 'test')\n",
        "\n",
        "train_writer = tf.summary.create_file_writer(tb_train_path)\n",
        "test_writer = tf.summary.create_file_writer(tb_test_path)\n",
        "train_step = test_step = 0\n",
        "\n",
        "\"\"\"\n",
        "########################################################\n",
        "##########  configure model inputs and params  #########\n",
        "########################################################\n",
        "\"\"\"\n",
        "\n",
        "blocks_to_train = []\n",
        "lr = 1e-4\n",
        "optimizer = SGD(lr=lr, decay=1e-6,momentum=0.9,nesterov=True)\n",
        "# optimizer = Adam(learning_rate=0.0001)\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "acc_metric = tf.keras.metrics.CategoricalCrossentropy()\n",
        "model = create_model(optimizer, name=model_name, include_compile=False,\n",
        "                    blocks_to_train=blocks_to_train)\n",
        "\n",
        "\"\"\" \n",
        "########################################################\n",
        "##################  Training Loop  #####################\n",
        "########################################################\n",
        "\"\"\"\n",
        "\n",
        "metrics = {'acc': 0.0, 'loss': 0.0, 'val_acc': 0.0, 'val_loss': 0.0, 'lr': lr}\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Iterate through the training set\n",
        "    print(\"\\epoch {}/{}\".format(epoch+1,n_epochs))\n",
        "    progress_bar = Progbar(train_size, stateful_metrics=list(metrics.keys()))\n",
        "\n",
        "    train_gen = train_ds.take(train_size//batch_size)\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_gen):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(x, training=True)\n",
        "            loss = loss_fn(y, y_pred)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        acc_metric.update_state(y, y_pred)\n",
        "        train_step += 1\n",
        "        progress_bar.update(batch_idx*batch_size, values=[('acc',acc_metric.result()), \n",
        "                                       ('loss', loss)])\n",
        "        # print(batch_idx, \" / \", len(train_gen))\n",
        "\n",
        "    with train_writer.as_default():\n",
        "        tf.summary.scalar(\"Loss\", loss, step=epoch)\n",
        "        tf.summary.scalar(\n",
        "            \"Accuracy\", acc_metric.result(), step=epoch\n",
        "        )\n",
        "        \n",
        "    # reset accuracy between epochs (and for testing and test)\n",
        "    \n",
        "    acc_metric.reset_states()\n",
        "\n",
        "    \"\"\" \n",
        "    ########################################################\n",
        "    #####################  Validation  #####################\n",
        "    ########################################################\n",
        "    \"\"\"\n",
        "\n",
        "    # acc_metric.reset_states()\n",
        "    val_gen = val_ds.take(val_size//batch_size)\n",
        "    for batch_idx, (x,y) in enumerate(val_gen):\n",
        "        confusion = np.zeros((len(labels), len(labels)))\n",
        "        figure = image_to_grid(x.numpy(),\n",
        "                               y.numpy(), \n",
        "                                class_names=list(labels.keys()))\n",
        "        y_pred = model(x, \n",
        "                       training=False)\n",
        "        loss = loss_fn(y, y_pred)\n",
        "        acc_metric.update_state(y, \n",
        "                                y_pred)\n",
        "        confusion += get_confusion_matrix(y, y_pred, class_names=list(labels.keys()))\n",
        "\n",
        "        with test_writer.as_default():\n",
        "            tf.summary.scalar(\"Loss\", loss, step=epoch)\n",
        "            tf.summary.scalar(\"Accuracy\", acc_metric.result(), step=epoch)\n",
        "            tf.summary.image('Confusion Matrix',\n",
        "                            plot_confusion_matrix(confusion / batch_idx,\n",
        "                                                class_names=list(labels.keys())), step=epoch)\n",
        "            tf.summary.image(\"Visualize images\",plot_to_image(figure), step=epoch)\n",
        "\n",
        "    progress_bar.update(train_size, values=[('val_acc', acc_metric.result()), ('val_loss', loss)])\n",
        "\n",
        "    # reset accuracy between epochs (and for testing and test)\n",
        "    acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSUfe1Hm7P47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdtPEQgP7P2K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCy5fxMo7Pzb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVIPsmNk7Pwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOVLYnkp7PQ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQutiGGG7POM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7pwMWkh7PMU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd74NWMF7PI9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TckTDCR7PF8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4TxGZq77PDW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmW-GQpnzQWb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9stDd9Jos4O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCQHfBcJos1j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}